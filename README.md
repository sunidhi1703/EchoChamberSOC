# What I’ve Covered So Far

## Python Basics
I began with learning the fundamentals of Python — understanding data types, variables, loops, and functions. Also practiced writing conditional logic, working with lists and dictionaries, and performing basic string operations. 

## NumPy
Next, I explored NumPy, where I practiced creating and reshaping arrays, using operations like slicing, masking, and broadcasting. I also experimented with vectorized mathematical operations, aggregations like mean and sum, and performed matrix multiplications. 

## Pandas
In Pandas I learned how to create DataFrames, read CSVs, handle missing data, and perform filtering, sorting, and grouping operations. I explored `.loc` and `.iloc` for selecting rows/columns, merged datasets, and cleaned messy data to prepare it for analysis. 

## Matplotlib
I used Matplotlib to visualize data through line plots, bar graphs, histograms, and scatter plots. I also learned to customize visuals using labels, legends, colors, and subplots to make them presentation-ready. Plotting my data helped me understand patterns and distributions much faster than looking at raw tables. 

## Andrew Ng’s Machine Learning
Started with Machine Learning theory here. I learned the difference between supervised and unsupervised learning, how models minimize cost functions using gradient descent, and understood key concepts like bias, variance, and overfitting and underfitting.

## Artificial Neural Networks (ANNs)
I studied how a neural network works by mimicking biological neurons using layers and weights. I understood the flow of data from the input layer through hidden layers to the output, and how each layer applies transformations. Learnt how forward propagation computes predictions, while backpropagation helps update weights. Also learnt about activation functions like ReLU, sigmoid, and softmax.

## Recurrent Neural Networks (RNNs)
RNNs introduced the idea of memory and how previous time steps influence future predictions — something essential for tasks like text generation or stock prediction. I explored the basic RNN structure, understood how sequences flow through time, and how information is passed across steps. I also got introduced to LSTMs and why they’re preferred when longer memory is needed.
